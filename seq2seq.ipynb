{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from allennlp.models.encoder_decoders.copynet_seq2seq import CopyNetSeq2Seq\n",
    "\n",
    "\n",
    "import itertools\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from allennlp.data.dataset_readers.seq2seq import Seq2SeqDatasetReader\n",
    "from allennlp.data.dataset_readers.copynet_seq2seq import CopyNetDatasetReader\n",
    "\n",
    "from allennlp.data.iterators import BucketIterator\n",
    "from allennlp.data.token_indexers import SingleIdTokenIndexer\n",
    "from allennlp.data.tokenizers.character_tokenizer import CharacterTokenizer\n",
    "from allennlp.data.tokenizers.word_tokenizer import WordTokenizer\n",
    "from allennlp.data.vocabulary import Vocabulary\n",
    "from allennlp.nn.activations import Activation\n",
    "from allennlp.models.encoder_decoders.simple_seq2seq import SimpleSeq2Seq\n",
    "from allennlp.models.encoder_decoders.copynet_seq2seq import CopyNetSeq2Seq\n",
    "\n",
    "\n",
    "from allennlp.modules.attention import LinearAttention, BilinearAttention, DotProductAttention\n",
    "from allennlp.modules.seq2seq_encoders import PytorchSeq2SeqWrapper, StackedSelfAttentionEncoder\n",
    "from allennlp.modules.text_field_embedders import BasicTextFieldEmbedder\n",
    "from allennlp.modules.token_embedders import Embedding\n",
    "from allennlp.predictors import Seq2SeqPredictor\n",
    "from allennlp.training.trainer import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#load from params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-03-17 16:56:17,044 - INFO - allennlp.common.params - random_seed = 13370\n",
      "2019-03-17 16:56:17,044 - INFO - allennlp.common.params - numpy_seed = 1337\n",
      "2019-03-17 16:56:17,044 - INFO - allennlp.common.params - pytorch_seed = 133\n",
      "2019-03-17 16:56:17,045 - INFO - allennlp.common.checks - Pytorch version: 1.0.0\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/alexanderleirvag/anaconda/envs/allennlp/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/Users/alexanderleirvag/anaconda/envs/allennlp/lib/python3.6/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/Users/alexanderleirvag/anaconda/envs/allennlp/lib/python3.6/site-packages/allennlp-0.8.3_unreleased-py3.6.egg/allennlp/run.py\", line 21, in <module>\n",
      "    run()\n",
      "  File \"/Users/alexanderleirvag/anaconda/envs/allennlp/lib/python3.6/site-packages/allennlp-0.8.3_unreleased-py3.6.egg/allennlp/run.py\", line 18, in run\n",
      "    main(prog=\"allennlp\")\n",
      "  File \"/Users/alexanderleirvag/anaconda/envs/allennlp/lib/python3.6/site-packages/allennlp-0.8.3_unreleased-py3.6.egg/allennlp/commands/__init__.py\", line 101, in main\n",
      "    args.func(args)\n",
      "  File \"/Users/alexanderleirvag/anaconda/envs/allennlp/lib/python3.6/site-packages/allennlp-0.8.3_unreleased-py3.6.egg/allennlp/commands/train.py\", line 103, in train_model_from_args\n",
      "    args.force)\n",
      "  File \"/Users/alexanderleirvag/anaconda/envs/allennlp/lib/python3.6/site-packages/allennlp-0.8.3_unreleased-py3.6.egg/allennlp/commands/train.py\", line 136, in train_model_from_file\n",
      "    return train_model(params, serialization_dir, file_friendly_logging, recover, force)\n",
      "  File \"/Users/alexanderleirvag/anaconda/envs/allennlp/lib/python3.6/site-packages/allennlp-0.8.3_unreleased-py3.6.egg/allennlp/commands/train.py\", line 170, in train_model\n",
      "    create_serialization_dir(params, serialization_dir, recover, force)\n",
      "  File \"/Users/alexanderleirvag/anaconda/envs/allennlp/lib/python3.6/site-packages/allennlp-0.8.3_unreleased-py3.6.egg/allennlp/training/util.py\", line 186, in create_serialization_dir\n",
      "    raise ConfigurationError(f\"Serialization directory ({serialization_dir}) already exists and is \"\n",
      "allennlp.common.checks.ConfigurationError: 'Serialization directory (./tmp_1/) already exists and is not empty. Specify --recover to recover training from existing output.'\n"
     ]
    }
   ],
   "source": [
    "!allennlp train copy_adv.json -s ./tmp_1/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-03-17 16:59:26,462 - INFO - allennlp.common.params - random_seed = 13370\n",
      "2019-03-17 16:59:26,462 - INFO - allennlp.common.params - numpy_seed = 1337\n",
      "2019-03-17 16:59:26,462 - INFO - allennlp.common.params - pytorch_seed = 133\n",
      "2019-03-17 16:59:26,463 - INFO - allennlp.common.checks - Pytorch version: 1.0.0\n",
      "2019-03-17 16:59:26,463 - INFO - allennlp.training.util - Recovering from prior training at ./tmp_1/.\n",
      "2019-03-17 16:59:26,483 - INFO - allennlp.common.params - evaluate_on_test = False\n",
      "2019-03-17 16:59:26,483 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.dataset_readers.dataset_reader.DatasetReader'> from params {'source_token_indexers': {'tokens': {'namespace': 'source_tokens', 'type': 'single_id'}}, 'source_tokenizer': {'type': 'word', 'word_splitter': {'type': 'spacy'}}, 'target_namespace': 'target_tokens', 'target_tokenizer': {'type': 'word'}, 'type': 'copynet_seq2seq'} and extras {}\n",
      "2019-03-17 16:59:26,483 - INFO - allennlp.common.params - dataset_reader.type = copynet_seq2seq\n",
      "2019-03-17 16:59:26,483 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.dataset_readers.copynet_seq2seq.CopyNetDatasetReader'> from params {'source_token_indexers': {'tokens': {'namespace': 'source_tokens', 'type': 'single_id'}}, 'source_tokenizer': {'type': 'word', 'word_splitter': {'type': 'spacy'}}, 'target_namespace': 'target_tokens', 'target_tokenizer': {'type': 'word'}} and extras {}\n",
      "2019-03-17 16:59:26,484 - INFO - allennlp.common.params - dataset_reader.target_namespace = target_tokens\n",
      "2019-03-17 16:59:26,484 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.tokenizers.tokenizer.Tokenizer'> from params {'type': 'word', 'word_splitter': {'type': 'spacy'}} and extras {}\n",
      "2019-03-17 16:59:26,484 - INFO - allennlp.common.params - dataset_reader.source_tokenizer.type = word\n",
      "2019-03-17 16:59:26,484 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.tokenizers.word_tokenizer.WordTokenizer'> from params {'word_splitter': {'type': 'spacy'}} and extras {}\n",
      "2019-03-17 16:59:26,484 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.tokenizers.word_splitter.WordSplitter'> from params {'type': 'spacy'} and extras {}\n",
      "2019-03-17 16:59:26,484 - INFO - allennlp.common.params - dataset_reader.source_tokenizer.word_splitter.type = spacy\n",
      "2019-03-17 16:59:26,484 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.tokenizers.word_splitter.SpacyWordSplitter'> from params {} and extras {}\n",
      "2019-03-17 16:59:26,485 - INFO - allennlp.common.params - dataset_reader.source_tokenizer.word_splitter.language = en_core_web_sm\n",
      "2019-03-17 16:59:26,485 - INFO - allennlp.common.params - dataset_reader.source_tokenizer.word_splitter.pos_tags = False\n",
      "2019-03-17 16:59:26,485 - INFO - allennlp.common.params - dataset_reader.source_tokenizer.word_splitter.parse = False\n",
      "2019-03-17 16:59:26,485 - INFO - allennlp.common.params - dataset_reader.source_tokenizer.word_splitter.ner = False\n",
      "2019-03-17 16:59:26,780 - INFO - allennlp.common.params - dataset_reader.source_tokenizer.start_tokens = None\n",
      "2019-03-17 16:59:26,780 - INFO - allennlp.common.params - dataset_reader.source_tokenizer.end_tokens = None\n",
      "2019-03-17 16:59:26,780 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.tokenizers.tokenizer.Tokenizer'> from params {'type': 'word'} and extras {}\n",
      "2019-03-17 16:59:26,780 - INFO - allennlp.common.params - dataset_reader.target_tokenizer.type = word\n",
      "2019-03-17 16:59:26,780 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.tokenizers.word_tokenizer.WordTokenizer'> from params {} and extras {}\n",
      "2019-03-17 16:59:26,781 - INFO - allennlp.common.params - dataset_reader.target_tokenizer.start_tokens = None\n",
      "2019-03-17 16:59:26,781 - INFO - allennlp.common.params - dataset_reader.target_tokenizer.end_tokens = None\n",
      "2019-03-17 16:59:26,781 - INFO - allennlp.common.from_params - instantiating class allennlp.data.token_indexers.token_indexer.TokenIndexer from params {'namespace': 'source_tokens', 'type': 'single_id'} and extras {}\n",
      "2019-03-17 16:59:26,781 - INFO - allennlp.common.params - dataset_reader.source_token_indexers.tokens.type = single_id\n",
      "2019-03-17 16:59:26,781 - INFO - allennlp.common.from_params - instantiating class allennlp.data.token_indexers.single_id_token_indexer.SingleIdTokenIndexer from params {'namespace': 'source_tokens'} and extras {}\n",
      "2019-03-17 16:59:26,781 - INFO - allennlp.common.params - dataset_reader.source_token_indexers.tokens.namespace = source_tokens\n",
      "2019-03-17 16:59:26,781 - INFO - allennlp.common.params - dataset_reader.source_token_indexers.tokens.lowercase_tokens = False\n",
      "2019-03-17 16:59:26,781 - INFO - allennlp.common.params - dataset_reader.source_token_indexers.tokens.start_tokens = None\n",
      "2019-03-17 16:59:26,781 - INFO - allennlp.common.params - dataset_reader.source_token_indexers.tokens.end_tokens = None\n",
      "2019-03-17 16:59:26,782 - INFO - allennlp.common.params - dataset_reader.lazy = False\n",
      "2019-03-17 16:59:26,782 - INFO - allennlp.common.params - validation_dataset_reader = None\n",
      "2019-03-17 16:59:26,782 - INFO - allennlp.common.params - train_data_path = small_test.tsv\n",
      "2019-03-17 16:59:26,782 - INFO - allennlp.training.util - Reading training data from small_test.tsv\n",
      "0it [00:00, ?it/s]2019-03-17 16:59:26,782 - INFO - allennlp.data.dataset_readers.copynet_seq2seq - Reading instances from lines in file at: small_test.tsv\n",
      "100it [00:00, 210.20it/s]\n",
      "2019-03-17 16:59:27,258 - INFO - allennlp.common.params - validation_data_path = small_test.tsv\n",
      "2019-03-17 16:59:27,258 - INFO - allennlp.training.util - Reading validation data from small_test.tsv\n",
      "0it [00:00, ?it/s]2019-03-17 16:59:27,258 - INFO - allennlp.data.dataset_readers.copynet_seq2seq - Reading instances from lines in file at: small_test.tsv\n",
      "100it [00:00, 205.62it/s]\n",
      "2019-03-17 16:59:27,745 - INFO - allennlp.common.params - test_data_path = None\n",
      "2019-03-17 16:59:27,745 - INFO - allennlp.training.trainer - From dataset instances, validation, train will be considered for vocabulary creation.\n",
      "2019-03-17 16:59:27,745 - INFO - allennlp.data.vocabulary - Loading token dictionary from ./tmp_1/vocabulary.\n",
      "2019-03-17 16:59:27,749 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.models.model.Model'> from params {'attention': {'matrix_dim': 10, 'type': 'bilinear', 'vector_dim': 10}, 'beam_size': 5, 'encoder': {'feedforward_hidden_dim': 128, 'hidden_dim': 10, 'input_dim': 25, 'num_attention_heads': 8, 'num_layers': 1, 'projection_dim': 128, 'type': 'stacked_self_attention'}, 'max_decoding_steps': 50, 'source_embedder': {'tokens': {'embedding_dim': 25, 'trainable': True, 'type': 'embedding', 'vocab_namespace': 'source_tokens'}}, 'target_embedding_dim': 10, 'type': 'copynet_seq2seq'} and extras {'vocab': Vocabulary with namespaces:  target_tokens, Size: 533 || source_tokens, Size: 4205 || Non Padded Namespaces: {'*tags', '*labels'}}\n",
      "2019-03-17 16:59:27,750 - INFO - allennlp.common.params - model.type = copynet_seq2seq\n",
      "2019-03-17 16:59:27,750 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.models.encoder_decoders.copynet_seq2seq.CopyNetSeq2Seq'> from params {'attention': {'matrix_dim': 10, 'type': 'bilinear', 'vector_dim': 10}, 'beam_size': 5, 'encoder': {'feedforward_hidden_dim': 128, 'hidden_dim': 10, 'input_dim': 25, 'num_attention_heads': 8, 'num_layers': 1, 'projection_dim': 128, 'type': 'stacked_self_attention'}, 'max_decoding_steps': 50, 'source_embedder': {'tokens': {'embedding_dim': 25, 'trainable': True, 'type': 'embedding', 'vocab_namespace': 'source_tokens'}}, 'target_embedding_dim': 10} and extras {'vocab': Vocabulary with namespaces:  target_tokens, Size: 533 || source_tokens, Size: 4205 || Non Padded Namespaces: {'*tags', '*labels'}}\n",
      "2019-03-17 16:59:27,750 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.text_field_embedders.text_field_embedder.TextFieldEmbedder'> from params {'tokens': {'embedding_dim': 25, 'trainable': True, 'type': 'embedding', 'vocab_namespace': 'source_tokens'}} and extras {'vocab': Vocabulary with namespaces:  target_tokens, Size: 533 || source_tokens, Size: 4205 || Non Padded Namespaces: {'*tags', '*labels'}}\n",
      "2019-03-17 16:59:27,750 - INFO - allennlp.common.params - model.source_embedder.type = basic\n",
      "2019-03-17 16:59:27,750 - INFO - allennlp.common.params - model.source_embedder.embedder_to_indexer_map = None\n",
      "2019-03-17 16:59:27,750 - INFO - allennlp.common.params - model.source_embedder.allow_unmatched_keys = False\n",
      "2019-03-17 16:59:27,751 - INFO - allennlp.common.params - model.source_embedder.token_embedders = None\n",
      "2019-03-17 16:59:27,751 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.token_embedders.token_embedder.TokenEmbedder'> from params {'embedding_dim': 25, 'trainable': True, 'type': 'embedding', 'vocab_namespace': 'source_tokens'} and extras {'vocab': Vocabulary with namespaces:  target_tokens, Size: 533 || source_tokens, Size: 4205 || Non Padded Namespaces: {'*tags', '*labels'}}\n",
      "2019-03-17 16:59:27,751 - INFO - allennlp.common.params - model.source_embedder.tokens.type = embedding\n",
      "2019-03-17 16:59:27,751 - INFO - allennlp.common.params - model.source_embedder.tokens.num_embeddings = None\n",
      "2019-03-17 16:59:27,751 - INFO - allennlp.common.params - model.source_embedder.tokens.vocab_namespace = source_tokens\n",
      "2019-03-17 16:59:27,751 - INFO - allennlp.common.params - model.source_embedder.tokens.embedding_dim = 25\n",
      "2019-03-17 16:59:27,751 - INFO - allennlp.common.params - model.source_embedder.tokens.pretrained_file = None\n",
      "2019-03-17 16:59:27,751 - INFO - allennlp.common.params - model.source_embedder.tokens.projection_dim = None\n",
      "2019-03-17 16:59:27,751 - INFO - allennlp.common.params - model.source_embedder.tokens.trainable = True\n",
      "2019-03-17 16:59:27,751 - INFO - allennlp.common.params - model.source_embedder.tokens.padding_index = None\n",
      "2019-03-17 16:59:27,752 - INFO - allennlp.common.params - model.source_embedder.tokens.max_norm = None\n",
      "2019-03-17 16:59:27,752 - INFO - allennlp.common.params - model.source_embedder.tokens.norm_type = 2.0\n",
      "2019-03-17 16:59:27,752 - INFO - allennlp.common.params - model.source_embedder.tokens.scale_grad_by_freq = False\n",
      "2019-03-17 16:59:27,752 - INFO - allennlp.common.params - model.source_embedder.tokens.sparse = False\n",
      "2019-03-17 16:59:27,753 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.seq2seq_encoders.seq2seq_encoder.Seq2SeqEncoder'> from params {'feedforward_hidden_dim': 128, 'hidden_dim': 10, 'input_dim': 25, 'num_attention_heads': 8, 'num_layers': 1, 'projection_dim': 128, 'type': 'stacked_self_attention'} and extras {'vocab': Vocabulary with namespaces:  target_tokens, Size: 533 || source_tokens, Size: 4205 || Non Padded Namespaces: {'*tags', '*labels'}}\n",
      "2019-03-17 16:59:27,753 - INFO - allennlp.common.params - model.encoder.type = stacked_self_attention\n",
      "2019-03-17 16:59:27,754 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.seq2seq_encoders.stacked_self_attention.StackedSelfAttentionEncoder'> from params {'feedforward_hidden_dim': 128, 'hidden_dim': 10, 'input_dim': 25, 'num_attention_heads': 8, 'num_layers': 1, 'projection_dim': 128} and extras {'vocab': Vocabulary with namespaces:  target_tokens, Size: 533 || source_tokens, Size: 4205 || Non Padded Namespaces: {'*tags', '*labels'}}\n",
      "2019-03-17 16:59:27,754 - INFO - allennlp.common.params - model.encoder.input_dim = 25\n",
      "2019-03-17 16:59:27,754 - INFO - allennlp.common.params - model.encoder.hidden_dim = 10\n",
      "2019-03-17 16:59:27,754 - INFO - allennlp.common.params - model.encoder.projection_dim = 128\n",
      "2019-03-17 16:59:27,754 - INFO - allennlp.common.params - model.encoder.feedforward_hidden_dim = 128\n",
      "2019-03-17 16:59:27,754 - INFO - allennlp.common.params - model.encoder.num_layers = 1\n",
      "2019-03-17 16:59:27,754 - INFO - allennlp.common.params - model.encoder.num_attention_heads = 8\n",
      "2019-03-17 16:59:27,754 - INFO - allennlp.common.params - model.encoder.use_positional_encoding = True\n",
      "2019-03-17 16:59:27,754 - INFO - allennlp.common.params - model.encoder.dropout_prob = 0.1\n",
      "2019-03-17 16:59:27,754 - INFO - allennlp.common.params - model.encoder.residual_dropout_prob = 0.2\n",
      "2019-03-17 16:59:27,754 - INFO - allennlp.common.params - model.encoder.attention_dropout_prob = 0.1\n",
      "2019-03-17 16:59:27,756 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.attention.attention.Attention'> from params {'matrix_dim': 10, 'type': 'bilinear', 'vector_dim': 10} and extras {'vocab': Vocabulary with namespaces:  target_tokens, Size: 533 || source_tokens, Size: 4205 || Non Padded Namespaces: {'*tags', '*labels'}}\n",
      "2019-03-17 16:59:27,756 - INFO - allennlp.common.params - model.attention.type = bilinear\n",
      "2019-03-17 16:59:27,756 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.attention.bilinear_attention.BilinearAttention'> from params {'matrix_dim': 10, 'vector_dim': 10} and extras {'vocab': Vocabulary with namespaces:  target_tokens, Size: 533 || source_tokens, Size: 4205 || Non Padded Namespaces: {'*tags', '*labels'}}\n",
      "2019-03-17 16:59:27,756 - INFO - allennlp.common.params - model.attention.vector_dim = 10\n",
      "2019-03-17 16:59:27,756 - INFO - allennlp.common.params - model.attention.matrix_dim = 10\n",
      "2019-03-17 16:59:27,756 - INFO - allennlp.common.params - model.attention.normalize = True\n",
      "2019-03-17 16:59:27,756 - INFO - allennlp.common.params - model.beam_size = 5\n",
      "2019-03-17 16:59:27,756 - INFO - allennlp.common.params - model.max_decoding_steps = 50\n",
      "2019-03-17 16:59:27,756 - INFO - allennlp.common.params - model.target_embedding_dim = 10\n",
      "2019-03-17 16:59:27,757 - INFO - allennlp.common.params - model.copy_token = @COPY@\n",
      "2019-03-17 16:59:27,757 - INFO - allennlp.common.params - model.source_namespace = source_tokens\n",
      "2019-03-17 16:59:27,757 - INFO - allennlp.common.params - model.target_namespace = target_tokens\n",
      "2019-03-17 16:59:27,757 - INFO - allennlp.nn.initializers - Initializing parameters\n",
      "2019-03-17 16:59:27,758 - INFO - allennlp.nn.initializers - Done initializing parameters; the following parameters are using their default initialization from their code\n",
      "2019-03-17 16:59:27,758 - INFO - allennlp.nn.initializers -    _attention._bias\n",
      "2019-03-17 16:59:27,758 - INFO - allennlp.nn.initializers -    _attention._weight_matrix\n",
      "2019-03-17 16:59:27,758 - INFO - allennlp.nn.initializers -    _decoder_cell.bias_hh\n",
      "2019-03-17 16:59:27,758 - INFO - allennlp.nn.initializers -    _decoder_cell.bias_ih\n",
      "2019-03-17 16:59:27,758 - INFO - allennlp.nn.initializers -    _decoder_cell.weight_hh\n",
      "2019-03-17 16:59:27,758 - INFO - allennlp.nn.initializers -    _decoder_cell.weight_ih\n",
      "2019-03-17 16:59:27,758 - INFO - allennlp.nn.initializers -    _encoder.feedforward_0._linear_layers.0.bias\n",
      "2019-03-17 16:59:27,758 - INFO - allennlp.nn.initializers -    _encoder.feedforward_0._linear_layers.0.weight\n",
      "2019-03-17 16:59:27,758 - INFO - allennlp.nn.initializers -    _encoder.feedforward_0._linear_layers.1.bias\n",
      "2019-03-17 16:59:27,758 - INFO - allennlp.nn.initializers -    _encoder.feedforward_0._linear_layers.1.weight\n",
      "2019-03-17 16:59:27,758 - INFO - allennlp.nn.initializers -    _encoder.feedforward_layer_norm_0.beta\n",
      "2019-03-17 16:59:27,758 - INFO - allennlp.nn.initializers -    _encoder.feedforward_layer_norm_0.gamma\n",
      "2019-03-17 16:59:27,758 - INFO - allennlp.nn.initializers -    _encoder.layer_norm_0.beta\n",
      "2019-03-17 16:59:27,758 - INFO - allennlp.nn.initializers -    _encoder.layer_norm_0.gamma\n",
      "2019-03-17 16:59:27,758 - INFO - allennlp.nn.initializers -    _encoder.self_attention_0._combined_projection.bias\n",
      "2019-03-17 16:59:27,758 - INFO - allennlp.nn.initializers -    _encoder.self_attention_0._combined_projection.weight\n",
      "2019-03-17 16:59:27,759 - INFO - allennlp.nn.initializers -    _encoder.self_attention_0._output_projection.bias\n",
      "2019-03-17 16:59:27,759 - INFO - allennlp.nn.initializers -    _encoder.self_attention_0._output_projection.weight\n",
      "2019-03-17 16:59:27,759 - INFO - allennlp.nn.initializers -    _input_projection_layer.bias\n",
      "2019-03-17 16:59:27,759 - INFO - allennlp.nn.initializers -    _input_projection_layer.weight\n",
      "2019-03-17 16:59:27,759 - INFO - allennlp.nn.initializers -    _output_copying_layer.bias\n",
      "2019-03-17 16:59:27,759 - INFO - allennlp.nn.initializers -    _output_copying_layer.weight\n",
      "2019-03-17 16:59:27,759 - INFO - allennlp.nn.initializers -    _output_generation_layer.bias\n",
      "2019-03-17 16:59:27,759 - INFO - allennlp.nn.initializers -    _output_generation_layer.weight\n",
      "2019-03-17 16:59:27,759 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.weight\n",
      "2019-03-17 16:59:27,759 - INFO - allennlp.nn.initializers -    _target_embedder.weight\n",
      "2019-03-17 16:59:27,759 - INFO - root - Loading a model trained before embedding extension was implemented; pass an explicit vocab namespace if you want to extend the vocabulary.\n",
      "2019-03-17 16:59:27,759 - WARNING - root - vocabulary serialization directory ./tmp_1/vocabulary is not empty\n",
      "2019-03-17 16:59:27,773 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.iterators.data_iterator.DataIterator'> from params {'batch_size': 80, 'padding_noise': 0, 'sorting_keys': [['source_tokens', 'num_tokens']], 'type': 'bucket'} and extras {}\n",
      "2019-03-17 16:59:27,773 - INFO - allennlp.common.params - iterator.type = bucket\n",
      "2019-03-17 16:59:27,773 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.iterators.bucket_iterator.BucketIterator'> from params {'batch_size': 80, 'padding_noise': 0, 'sorting_keys': [['source_tokens', 'num_tokens']]} and extras {}\n",
      "2019-03-17 16:59:27,774 - INFO - allennlp.common.params - iterator.sorting_keys = [['source_tokens', 'num_tokens']]\n",
      "2019-03-17 16:59:27,774 - INFO - allennlp.common.params - iterator.padding_noise = 0\n",
      "2019-03-17 16:59:27,774 - INFO - allennlp.common.params - iterator.biggest_batch_first = False\n",
      "2019-03-17 16:59:27,774 - INFO - allennlp.common.params - iterator.batch_size = 80\n",
      "2019-03-17 16:59:27,774 - INFO - allennlp.common.params - iterator.instances_per_epoch = None\n",
      "2019-03-17 16:59:27,774 - INFO - allennlp.common.params - iterator.max_instances_in_memory = None\n",
      "2019-03-17 16:59:27,774 - INFO - allennlp.common.params - iterator.cache_instances = False\n",
      "2019-03-17 16:59:27,774 - INFO - allennlp.common.params - iterator.track_epoch = False\n",
      "2019-03-17 16:59:27,774 - INFO - allennlp.common.params - iterator.maximum_samples_per_batch = None\n",
      "2019-03-17 16:59:27,774 - INFO - allennlp.common.params - validation_iterator = None\n",
      "2019-03-17 16:59:27,774 - INFO - allennlp.common.params - trainer.no_grad = ()\n",
      "2019-03-17 16:59:27,775 - INFO - allennlp.training.trainer - Following parameters are Frozen  (without gradient):\n",
      "2019-03-17 16:59:27,775 - INFO - allennlp.training.trainer - Following parameters are Tunable (with gradient):\n",
      "2019-03-17 16:59:27,775 - INFO - allennlp.training.trainer - _source_embedder.token_embedder_tokens.weight\n",
      "2019-03-17 16:59:27,775 - INFO - allennlp.training.trainer - _encoder.feedforward_0._linear_layers.0.weight\n",
      "2019-03-17 16:59:27,775 - INFO - allennlp.training.trainer - _encoder.feedforward_0._linear_layers.0.bias\n",
      "2019-03-17 16:59:27,775 - INFO - allennlp.training.trainer - _encoder.feedforward_0._linear_layers.1.weight\n",
      "2019-03-17 16:59:27,775 - INFO - allennlp.training.trainer - _encoder.feedforward_0._linear_layers.1.bias\n",
      "2019-03-17 16:59:27,775 - INFO - allennlp.training.trainer - _encoder.feedforward_layer_norm_0.gamma\n",
      "2019-03-17 16:59:27,775 - INFO - allennlp.training.trainer - _encoder.feedforward_layer_norm_0.beta\n",
      "2019-03-17 16:59:27,775 - INFO - allennlp.training.trainer - _encoder.self_attention_0._combined_projection.weight\n",
      "2019-03-17 16:59:27,775 - INFO - allennlp.training.trainer - _encoder.self_attention_0._combined_projection.bias\n",
      "2019-03-17 16:59:27,775 - INFO - allennlp.training.trainer - _encoder.self_attention_0._output_projection.weight\n",
      "2019-03-17 16:59:27,775 - INFO - allennlp.training.trainer - _encoder.self_attention_0._output_projection.bias\n",
      "2019-03-17 16:59:27,775 - INFO - allennlp.training.trainer - _encoder.layer_norm_0.gamma\n",
      "2019-03-17 16:59:27,775 - INFO - allennlp.training.trainer - _encoder.layer_norm_0.beta\n",
      "2019-03-17 16:59:27,775 - INFO - allennlp.training.trainer - _target_embedder.weight\n",
      "2019-03-17 16:59:27,775 - INFO - allennlp.training.trainer - _attention._weight_matrix\n",
      "2019-03-17 16:59:27,775 - INFO - allennlp.training.trainer - _attention._bias\n",
      "2019-03-17 16:59:27,776 - INFO - allennlp.training.trainer - _input_projection_layer.weight\n",
      "2019-03-17 16:59:27,776 - INFO - allennlp.training.trainer - _input_projection_layer.bias\n",
      "2019-03-17 16:59:27,776 - INFO - allennlp.training.trainer - _decoder_cell.weight_ih\n",
      "2019-03-17 16:59:27,776 - INFO - allennlp.training.trainer - _decoder_cell.weight_hh\n",
      "2019-03-17 16:59:27,776 - INFO - allennlp.training.trainer - _decoder_cell.bias_ih\n",
      "2019-03-17 16:59:27,776 - INFO - allennlp.training.trainer - _decoder_cell.bias_hh\n",
      "2019-03-17 16:59:27,776 - INFO - allennlp.training.trainer - _output_generation_layer.weight\n",
      "2019-03-17 16:59:27,776 - INFO - allennlp.training.trainer - _output_generation_layer.bias\n",
      "2019-03-17 16:59:27,776 - INFO - allennlp.training.trainer - _output_copying_layer.weight\n",
      "2019-03-17 16:59:27,776 - INFO - allennlp.training.trainer - _output_copying_layer.bias\n",
      "2019-03-17 16:59:27,776 - INFO - allennlp.common.params - trainer.patience = 10\n",
      "2019-03-17 16:59:27,776 - INFO - allennlp.common.params - trainer.validation_metric = -loss\n",
      "2019-03-17 16:59:27,776 - INFO - allennlp.common.params - trainer.shuffle = True\n",
      "2019-03-17 16:59:27,776 - INFO - allennlp.common.params - trainer.num_epochs = 10\n",
      "2019-03-17 16:59:27,776 - INFO - allennlp.common.params - trainer.cuda_device = -1\n",
      "2019-03-17 16:59:27,776 - INFO - allennlp.common.params - trainer.grad_norm = None\n",
      "2019-03-17 16:59:27,776 - INFO - allennlp.common.params - trainer.grad_clipping = None\n",
      "2019-03-17 16:59:27,776 - INFO - allennlp.common.params - trainer.learning_rate_scheduler = None\n",
      "2019-03-17 16:59:27,777 - INFO - allennlp.common.params - trainer.momentum_scheduler = None\n",
      "2019-03-17 16:59:27,777 - INFO - allennlp.common.params - trainer.optimizer.type = adam\n",
      "2019-03-17 16:59:27,777 - INFO - allennlp.common.params - trainer.optimizer.parameter_groups = None\n",
      "2019-03-17 16:59:27,777 - INFO - allennlp.training.optimizers - Number of trainable parameters: 127891\n",
      "2019-03-17 16:59:27,777 - INFO - allennlp.common.params - trainer.optimizer.infer_type_and_cast = True\n",
      "2019-03-17 16:59:27,778 - INFO - allennlp.common.params - Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.\n",
      "2019-03-17 16:59:27,778 - INFO - allennlp.common.params - CURRENTLY DEFINED PARAMETERS: \n",
      "2019-03-17 16:59:27,778 - INFO - allennlp.common.params - trainer.optimizer.lr = 0.1\n",
      "2019-03-17 16:59:27,778 - INFO - allennlp.common.params - trainer.num_serialized_models_to_keep = 20\n",
      "2019-03-17 16:59:27,778 - INFO - allennlp.common.params - trainer.keep_serialized_model_every_num_seconds = None\n",
      "2019-03-17 16:59:27,778 - INFO - allennlp.common.params - trainer.model_save_interval = None\n",
      "2019-03-17 16:59:27,778 - INFO - allennlp.common.params - trainer.summary_interval = 100\n",
      "2019-03-17 16:59:27,778 - INFO - allennlp.common.params - trainer.histogram_interval = None\n",
      "2019-03-17 16:59:27,778 - INFO - allennlp.common.params - trainer.should_log_parameter_statistics = True\n",
      "2019-03-17 16:59:27,778 - INFO - allennlp.common.params - trainer.should_log_learning_rate = False\n",
      "2019-03-17 16:59:27,778 - INFO - allennlp.common.params - trainer.log_batch_size_period = None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-03-17 16:59:27,788 - INFO - allennlp.training.trainer - Beginning training.\n",
      "2019-03-17 16:59:27,788 - INFO - allennlp.training.trainer - Epoch 2/9\n",
      "2019-03-17 16:59:27,788 - INFO - allennlp.training.trainer - Peak CPU memory usage MB: 251.703296\n",
      "2019-03-17 16:59:27,795 - INFO - allennlp.training.trainer - Training\n",
      "loss: 67.6926 ||: 100%|##########| 2/2 [00:05<00:00,  2.57s/it]\n",
      "2019-03-17 16:59:33,722 - INFO - allennlp.training.trainer - Validating\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]^C\n",
      "2019-03-17 16:59:40,396 - INFO - root - Training interrupted by the user. Attempting to create a model archive using the current best epoch weights.\n",
      "2019-03-17 16:59:40,397 - INFO - allennlp.models.archival - archiving weights and vocabulary to ./tmp_1/model.tar.gz\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/alexanderleirvag/anaconda/envs/allennlp/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/Users/alexanderleirvag/anaconda/envs/allennlp/lib/python3.6/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/Users/alexanderleirvag/anaconda/envs/allennlp/lib/python3.6/site-packages/allennlp-0.8.3_unreleased-py3.6.egg/allennlp/run.py\", line 21, in <module>\n",
      "    run()\n",
      "  File \"/Users/alexanderleirvag/anaconda/envs/allennlp/lib/python3.6/site-packages/allennlp-0.8.3_unreleased-py3.6.egg/allennlp/run.py\", line 18, in run\n",
      "    main(prog=\"allennlp\")\n",
      "  File \"/Users/alexanderleirvag/anaconda/envs/allennlp/lib/python3.6/site-packages/allennlp-0.8.3_unreleased-py3.6.egg/allennlp/commands/__init__.py\", line 101, in main\n",
      "    args.func(args)\n",
      "  File \"/Users/alexanderleirvag/anaconda/envs/allennlp/lib/python3.6/site-packages/allennlp-0.8.3_unreleased-py3.6.egg/allennlp/commands/train.py\", line 103, in train_model_from_args\n",
      "    args.force)\n",
      "  File \"/Users/alexanderleirvag/anaconda/envs/allennlp/lib/python3.6/site-packages/allennlp-0.8.3_unreleased-py3.6.egg/allennlp/commands/train.py\", line 136, in train_model_from_file\n",
      "    return train_model(params, serialization_dir, file_friendly_logging, recover, force)\n",
      "  File \"/Users/alexanderleirvag/anaconda/envs/allennlp/lib/python3.6/site-packages/allennlp-0.8.3_unreleased-py3.6.egg/allennlp/commands/train.py\", line 204, in train_model\n",
      "    metrics = trainer.train()\n",
      "  File \"/Users/alexanderleirvag/anaconda/envs/allennlp/lib/python3.6/site-packages/allennlp-0.8.3_unreleased-py3.6.egg/allennlp/training/trainer.py\", line 477, in train\n",
      "    val_loss, num_batches = self._validation_loss()\n",
      "  File \"/Users/alexanderleirvag/anaconda/envs/allennlp/lib/python3.6/site-packages/allennlp-0.8.3_unreleased-py3.6.egg/allennlp/training/trainer.py\", line 414, in _validation_loss\n",
      "    loss = self.batch_loss(batch_group, for_training=False)\n",
      "  File \"/Users/alexanderleirvag/anaconda/envs/allennlp/lib/python3.6/site-packages/allennlp-0.8.3_unreleased-py3.6.egg/allennlp/training/trainer.py\", line 247, in batch_loss\n",
      "    output_dict = self.model(**batch)\n",
      "  File \"/Users/alexanderleirvag/anaconda/envs/allennlp/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 489, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/Users/alexanderleirvag/anaconda/envs/allennlp/lib/python3.6/site-packages/allennlp-0.8.3_unreleased-py3.6.egg/allennlp/models/encoder_decoders/copynet_seq2seq.py\", line 204, in forward\n",
      "    predictions = self._forward_beam_search(state)\n",
      "  File \"/Users/alexanderleirvag/anaconda/envs/allennlp/lib/python3.6/site-packages/allennlp-0.8.3_unreleased-py3.6.egg/allennlp/models/encoder_decoders/copynet_seq2seq.py\", line 519, in _forward_beam_search\n",
      "    start_predictions, state, self.take_search_step)\n",
      "  File \"/Users/alexanderleirvag/anaconda/envs/allennlp/lib/python3.6/site-packages/allennlp-0.8.3_unreleased-py3.6.egg/allennlp/nn/beam_search.py\", line 150, in search\n",
      "    class_log_probabilities, state = step(last_predictions, state)\n",
      "  File \"/Users/alexanderleirvag/anaconda/envs/allennlp/lib/python3.6/site-packages/allennlp-0.8.3_unreleased-py3.6.egg/allennlp/models/encoder_decoders/copynet_seq2seq.py\", line 772, in take_search_step\n",
      "    final_log_probs = self._gather_final_log_probs(generation_log_probs, copy_log_probs, state)\n",
      "  File \"/Users/alexanderleirvag/anaconda/envs/allennlp/lib/python3.6/site-packages/allennlp-0.8.3_unreleased-py3.6.egg/allennlp/models/encoder_decoders/copynet_seq2seq.py\", line 669, in _gather_final_log_probs\n",
      "    source_previous_occurences = source_token_ids[:, 0:i] == source_token_ids[:, i].unsqueeze(-1)\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!allennlp train ./tmp_1/config.json -s ./tmp_1/ --recover\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/17/2019 16:49:00 - INFO - allennlp.models.archival -   archiving weights and vocabulary to ./tmp_1/new_path.tar.gz\n"
     ]
    }
   ],
   "source": [
    "from allennlp.models.archival import load_archive, archive_model\n",
    "serialization_dir=\"./tmp_1\"\n",
    "archive_model(serialization_dir=serialization_dir,\n",
    "                      archive_path=serialization_dir + \"/new_path.tar.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/17/2019 18:09:11 - INFO - allennlp.models.archival -   loading archive file ./tmp_1/new_path.tar.gz\n",
      "03/17/2019 18:09:11 - INFO - allennlp.models.archival -   extracting archive file ./tmp_1/new_path.tar.gz to temp dir /var/folders/5z/k1wvytc11j9b735p7rssw__h0000gn/T/tmpb6elh3e0\n",
      "03/17/2019 18:09:11 - INFO - allennlp.common.params -   type = default\n",
      "03/17/2019 18:09:11 - INFO - allennlp.data.vocabulary -   Loading token dictionary from /var/folders/5z/k1wvytc11j9b735p7rssw__h0000gn/T/tmpb6elh3e0/vocabulary.\n",
      "03/17/2019 18:09:12 - INFO - allennlp.common.from_params -   instantiating class <class 'allennlp.models.model.Model'> from params {'attention': {'matrix_dim': 10, 'type': 'bilinear', 'vector_dim': 10}, 'beam_size': 5, 'encoder': {'feedforward_hidden_dim': 128, 'hidden_dim': 10, 'input_dim': 25, 'num_attention_heads': 8, 'num_layers': 1, 'projection_dim': 128, 'type': 'stacked_self_attention'}, 'max_decoding_steps': 50, 'source_embedder': {'tokens': {'embedding_dim': 25, 'trainable': True, 'type': 'embedding', 'vocab_namespace': 'source_tokens'}}, 'target_embedding_dim': 10, 'type': 'copynet_seq2seq'} and extras {'vocab': Vocabulary with namespaces:  target_tokens, Size: 533 || source_tokens, Size: 4205 || Non Padded Namespaces: {'*labels', '*tags'}}\n",
      "03/17/2019 18:09:12 - INFO - allennlp.common.params -   model.type = copynet_seq2seq\n",
      "03/17/2019 18:09:12 - INFO - allennlp.common.from_params -   instantiating class <class 'allennlp.models.encoder_decoders.copynet_seq2seq.CopyNetSeq2Seq'> from params {'attention': {'matrix_dim': 10, 'type': 'bilinear', 'vector_dim': 10}, 'beam_size': 5, 'encoder': {'feedforward_hidden_dim': 128, 'hidden_dim': 10, 'input_dim': 25, 'num_attention_heads': 8, 'num_layers': 1, 'projection_dim': 128, 'type': 'stacked_self_attention'}, 'max_decoding_steps': 50, 'source_embedder': {'tokens': {'embedding_dim': 25, 'trainable': True, 'type': 'embedding', 'vocab_namespace': 'source_tokens'}}, 'target_embedding_dim': 10} and extras {'vocab': Vocabulary with namespaces:  target_tokens, Size: 533 || source_tokens, Size: 4205 || Non Padded Namespaces: {'*labels', '*tags'}}\n",
      "03/17/2019 18:09:12 - INFO - allennlp.common.from_params -   instantiating class <class 'allennlp.modules.text_field_embedders.text_field_embedder.TextFieldEmbedder'> from params {'tokens': {'embedding_dim': 25, 'trainable': True, 'type': 'embedding', 'vocab_namespace': 'source_tokens'}} and extras {'vocab': Vocabulary with namespaces:  target_tokens, Size: 533 || source_tokens, Size: 4205 || Non Padded Namespaces: {'*labels', '*tags'}}\n",
      "03/17/2019 18:09:12 - INFO - allennlp.common.params -   model.source_embedder.type = basic\n",
      "03/17/2019 18:09:12 - INFO - allennlp.common.params -   model.source_embedder.embedder_to_indexer_map = None\n",
      "03/17/2019 18:09:12 - INFO - allennlp.common.params -   model.source_embedder.allow_unmatched_keys = False\n",
      "03/17/2019 18:09:12 - INFO - allennlp.common.params -   model.source_embedder.token_embedders = None\n",
      "03/17/2019 18:09:12 - INFO - allennlp.common.from_params -   instantiating class <class 'allennlp.modules.token_embedders.token_embedder.TokenEmbedder'> from params {'embedding_dim': 25, 'trainable': True, 'type': 'embedding', 'vocab_namespace': 'source_tokens'} and extras {'vocab': Vocabulary with namespaces:  target_tokens, Size: 533 || source_tokens, Size: 4205 || Non Padded Namespaces: {'*labels', '*tags'}}\n",
      "03/17/2019 18:09:12 - INFO - allennlp.common.params -   model.source_embedder.tokens.type = embedding\n",
      "03/17/2019 18:09:12 - INFO - allennlp.common.params -   model.source_embedder.tokens.num_embeddings = None\n",
      "03/17/2019 18:09:12 - INFO - allennlp.common.params -   model.source_embedder.tokens.vocab_namespace = source_tokens\n",
      "03/17/2019 18:09:12 - INFO - allennlp.common.params -   model.source_embedder.tokens.embedding_dim = 25\n",
      "03/17/2019 18:09:12 - INFO - allennlp.common.params -   model.source_embedder.tokens.pretrained_file = None\n",
      "03/17/2019 18:09:12 - INFO - allennlp.common.params -   model.source_embedder.tokens.projection_dim = None\n",
      "03/17/2019 18:09:12 - INFO - allennlp.common.params -   model.source_embedder.tokens.trainable = True\n",
      "03/17/2019 18:09:12 - INFO - allennlp.common.params -   model.source_embedder.tokens.padding_index = None\n",
      "03/17/2019 18:09:12 - INFO - allennlp.common.params -   model.source_embedder.tokens.max_norm = None\n",
      "03/17/2019 18:09:12 - INFO - allennlp.common.params -   model.source_embedder.tokens.norm_type = 2.0\n",
      "03/17/2019 18:09:12 - INFO - allennlp.common.params -   model.source_embedder.tokens.scale_grad_by_freq = False\n",
      "03/17/2019 18:09:12 - INFO - allennlp.common.params -   model.source_embedder.tokens.sparse = False\n",
      "03/17/2019 18:09:12 - INFO - allennlp.common.from_params -   instantiating class <class 'allennlp.modules.seq2seq_encoders.seq2seq_encoder.Seq2SeqEncoder'> from params {'feedforward_hidden_dim': 128, 'hidden_dim': 10, 'input_dim': 25, 'num_attention_heads': 8, 'num_layers': 1, 'projection_dim': 128, 'type': 'stacked_self_attention'} and extras {'vocab': Vocabulary with namespaces:  target_tokens, Size: 533 || source_tokens, Size: 4205 || Non Padded Namespaces: {'*labels', '*tags'}}\n",
      "03/17/2019 18:09:12 - INFO - allennlp.common.params -   model.encoder.type = stacked_self_attention\n",
      "03/17/2019 18:09:12 - INFO - allennlp.common.from_params -   instantiating class <class 'allennlp.modules.seq2seq_encoders.stacked_self_attention.StackedSelfAttentionEncoder'> from params {'feedforward_hidden_dim': 128, 'hidden_dim': 10, 'input_dim': 25, 'num_attention_heads': 8, 'num_layers': 1, 'projection_dim': 128} and extras {'vocab': Vocabulary with namespaces:  target_tokens, Size: 533 || source_tokens, Size: 4205 || Non Padded Namespaces: {'*labels', '*tags'}}\n",
      "03/17/2019 18:09:12 - INFO - allennlp.common.params -   model.encoder.input_dim = 25\n",
      "03/17/2019 18:09:12 - INFO - allennlp.common.params -   model.encoder.hidden_dim = 10\n",
      "03/17/2019 18:09:12 - INFO - allennlp.common.params -   model.encoder.projection_dim = 128\n",
      "03/17/2019 18:09:12 - INFO - allennlp.common.params -   model.encoder.feedforward_hidden_dim = 128\n",
      "03/17/2019 18:09:12 - INFO - allennlp.common.params -   model.encoder.num_layers = 1\n",
      "03/17/2019 18:09:12 - INFO - allennlp.common.params -   model.encoder.num_attention_heads = 8\n",
      "03/17/2019 18:09:12 - INFO - allennlp.common.params -   model.encoder.use_positional_encoding = True\n",
      "03/17/2019 18:09:12 - INFO - allennlp.common.params -   model.encoder.dropout_prob = 0.1\n",
      "03/17/2019 18:09:12 - INFO - allennlp.common.params -   model.encoder.residual_dropout_prob = 0.2\n",
      "03/17/2019 18:09:12 - INFO - allennlp.common.params -   model.encoder.attention_dropout_prob = 0.1\n",
      "03/17/2019 18:09:12 - INFO - allennlp.common.from_params -   instantiating class <class 'allennlp.modules.attention.attention.Attention'> from params {'matrix_dim': 10, 'type': 'bilinear', 'vector_dim': 10} and extras {'vocab': Vocabulary with namespaces:  target_tokens, Size: 533 || source_tokens, Size: 4205 || Non Padded Namespaces: {'*labels', '*tags'}}\n",
      "03/17/2019 18:09:12 - INFO - allennlp.common.params -   model.attention.type = bilinear\n",
      "03/17/2019 18:09:12 - INFO - allennlp.common.from_params -   instantiating class <class 'allennlp.modules.attention.bilinear_attention.BilinearAttention'> from params {'matrix_dim': 10, 'vector_dim': 10} and extras {'vocab': Vocabulary with namespaces:  target_tokens, Size: 533 || source_tokens, Size: 4205 || Non Padded Namespaces: {'*labels', '*tags'}}\n",
      "03/17/2019 18:09:12 - INFO - allennlp.common.params -   model.attention.vector_dim = 10\n",
      "03/17/2019 18:09:12 - INFO - allennlp.common.params -   model.attention.matrix_dim = 10\n",
      "03/17/2019 18:09:12 - INFO - allennlp.common.params -   model.attention.normalize = True\n",
      "03/17/2019 18:09:12 - INFO - allennlp.common.params -   model.beam_size = 5\n",
      "03/17/2019 18:09:12 - INFO - allennlp.common.params -   model.max_decoding_steps = 50\n",
      "03/17/2019 18:09:12 - INFO - allennlp.common.params -   model.target_embedding_dim = 10\n",
      "03/17/2019 18:09:12 - INFO - allennlp.common.params -   model.copy_token = @COPY@\n",
      "03/17/2019 18:09:12 - INFO - allennlp.common.params -   model.source_namespace = source_tokens\n",
      "03/17/2019 18:09:12 - INFO - allennlp.common.params -   model.target_namespace = target_tokens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/17/2019 18:09:12 - INFO - allennlp.nn.initializers -   Initializing parameters\n",
      "03/17/2019 18:09:12 - INFO - allennlp.nn.initializers -   Done initializing parameters; the following parameters are using their default initialization from their code\n",
      "03/17/2019 18:09:12 - INFO - allennlp.nn.initializers -      _attention._bias\n",
      "03/17/2019 18:09:12 - INFO - allennlp.nn.initializers -      _attention._weight_matrix\n",
      "03/17/2019 18:09:12 - INFO - allennlp.nn.initializers -      _decoder_cell.bias_hh\n",
      "03/17/2019 18:09:12 - INFO - allennlp.nn.initializers -      _decoder_cell.bias_ih\n",
      "03/17/2019 18:09:12 - INFO - allennlp.nn.initializers -      _decoder_cell.weight_hh\n",
      "03/17/2019 18:09:12 - INFO - allennlp.nn.initializers -      _decoder_cell.weight_ih\n",
      "03/17/2019 18:09:12 - INFO - allennlp.nn.initializers -      _encoder.feedforward_0._linear_layers.0.bias\n",
      "03/17/2019 18:09:12 - INFO - allennlp.nn.initializers -      _encoder.feedforward_0._linear_layers.0.weight\n",
      "03/17/2019 18:09:12 - INFO - allennlp.nn.initializers -      _encoder.feedforward_0._linear_layers.1.bias\n",
      "03/17/2019 18:09:12 - INFO - allennlp.nn.initializers -      _encoder.feedforward_0._linear_layers.1.weight\n",
      "03/17/2019 18:09:12 - INFO - allennlp.nn.initializers -      _encoder.feedforward_layer_norm_0.beta\n",
      "03/17/2019 18:09:12 - INFO - allennlp.nn.initializers -      _encoder.feedforward_layer_norm_0.gamma\n",
      "03/17/2019 18:09:12 - INFO - allennlp.nn.initializers -      _encoder.layer_norm_0.beta\n",
      "03/17/2019 18:09:12 - INFO - allennlp.nn.initializers -      _encoder.layer_norm_0.gamma\n",
      "03/17/2019 18:09:12 - INFO - allennlp.nn.initializers -      _encoder.self_attention_0._combined_projection.bias\n",
      "03/17/2019 18:09:12 - INFO - allennlp.nn.initializers -      _encoder.self_attention_0._combined_projection.weight\n",
      "03/17/2019 18:09:12 - INFO - allennlp.nn.initializers -      _encoder.self_attention_0._output_projection.bias\n",
      "03/17/2019 18:09:12 - INFO - allennlp.nn.initializers -      _encoder.self_attention_0._output_projection.weight\n",
      "03/17/2019 18:09:12 - INFO - allennlp.nn.initializers -      _input_projection_layer.bias\n",
      "03/17/2019 18:09:12 - INFO - allennlp.nn.initializers -      _input_projection_layer.weight\n",
      "03/17/2019 18:09:12 - INFO - allennlp.nn.initializers -      _output_copying_layer.bias\n",
      "03/17/2019 18:09:12 - INFO - allennlp.nn.initializers -      _output_copying_layer.weight\n",
      "03/17/2019 18:09:12 - INFO - allennlp.nn.initializers -      _output_generation_layer.bias\n",
      "03/17/2019 18:09:12 - INFO - allennlp.nn.initializers -      _output_generation_layer.weight\n",
      "03/17/2019 18:09:12 - INFO - allennlp.nn.initializers -      _source_embedder.token_embedder_tokens.weight\n",
      "03/17/2019 18:09:12 - INFO - allennlp.nn.initializers -      _target_embedder.weight\n",
      "03/17/2019 18:09:12 - INFO - root -   Loading a model trained before embedding extension was implemented; pass an explicit vocab namespace if you want to extend the vocabulary.\n",
      "03/17/2019 18:09:12 - INFO - allennlp.common.from_params -   instantiating class <class 'allennlp.data.dataset_readers.dataset_reader.DatasetReader'> from params {'source_token_indexers': {'tokens': {'namespace': 'source_tokens', 'type': 'single_id'}}, 'source_tokenizer': {'type': 'word', 'word_splitter': {'type': 'spacy'}}, 'target_namespace': 'target_tokens', 'target_tokenizer': {'type': 'word'}, 'type': 'copynet_seq2seq'} and extras {}\n",
      "03/17/2019 18:09:12 - INFO - allennlp.common.params -   dataset_reader.type = copynet_seq2seq\n",
      "03/17/2019 18:09:12 - INFO - allennlp.common.from_params -   instantiating class <class 'allennlp.data.dataset_readers.copynet_seq2seq.CopyNetDatasetReader'> from params {'source_token_indexers': {'tokens': {'namespace': 'source_tokens', 'type': 'single_id'}}, 'source_tokenizer': {'type': 'word', 'word_splitter': {'type': 'spacy'}}, 'target_namespace': 'target_tokens', 'target_tokenizer': {'type': 'word'}} and extras {}\n",
      "03/17/2019 18:09:12 - INFO - allennlp.common.params -   dataset_reader.target_namespace = target_tokens\n",
      "03/17/2019 18:09:12 - INFO - allennlp.common.from_params -   instantiating class <class 'allennlp.data.tokenizers.tokenizer.Tokenizer'> from params {'type': 'word', 'word_splitter': {'type': 'spacy'}} and extras {}\n",
      "03/17/2019 18:09:12 - INFO - allennlp.common.params -   dataset_reader.source_tokenizer.type = word\n",
      "03/17/2019 18:09:12 - INFO - allennlp.common.from_params -   instantiating class <class 'allennlp.data.tokenizers.word_tokenizer.WordTokenizer'> from params {'word_splitter': {'type': 'spacy'}} and extras {}\n",
      "03/17/2019 18:09:12 - INFO - allennlp.common.from_params -   instantiating class <class 'allennlp.data.tokenizers.word_splitter.WordSplitter'> from params {'type': 'spacy'} and extras {}\n",
      "03/17/2019 18:09:12 - INFO - allennlp.common.params -   dataset_reader.source_tokenizer.word_splitter.type = spacy\n",
      "03/17/2019 18:09:12 - INFO - allennlp.common.from_params -   instantiating class <class 'allennlp.data.tokenizers.word_splitter.SpacyWordSplitter'> from params {} and extras {}\n",
      "03/17/2019 18:09:12 - INFO - allennlp.common.params -   dataset_reader.source_tokenizer.word_splitter.language = en_core_web_sm\n",
      "03/17/2019 18:09:12 - INFO - allennlp.common.params -   dataset_reader.source_tokenizer.word_splitter.pos_tags = False\n",
      "03/17/2019 18:09:12 - INFO - allennlp.common.params -   dataset_reader.source_tokenizer.word_splitter.parse = False\n",
      "03/17/2019 18:09:12 - INFO - allennlp.common.params -   dataset_reader.source_tokenizer.word_splitter.ner = False\n",
      "03/17/2019 18:09:12 - INFO - allennlp.common.params -   dataset_reader.source_tokenizer.start_tokens = None\n",
      "03/17/2019 18:09:12 - INFO - allennlp.common.params -   dataset_reader.source_tokenizer.end_tokens = None\n",
      "03/17/2019 18:09:12 - INFO - allennlp.common.from_params -   instantiating class <class 'allennlp.data.tokenizers.tokenizer.Tokenizer'> from params {'type': 'word'} and extras {}\n",
      "03/17/2019 18:09:12 - INFO - allennlp.common.params -   dataset_reader.target_tokenizer.type = word\n",
      "03/17/2019 18:09:12 - INFO - allennlp.common.from_params -   instantiating class <class 'allennlp.data.tokenizers.word_tokenizer.WordTokenizer'> from params {} and extras {}\n",
      "03/17/2019 18:09:12 - INFO - allennlp.common.params -   dataset_reader.target_tokenizer.start_tokens = None\n",
      "03/17/2019 18:09:12 - INFO - allennlp.common.params -   dataset_reader.target_tokenizer.end_tokens = None\n",
      "03/17/2019 18:09:12 - INFO - allennlp.common.from_params -   instantiating class allennlp.data.token_indexers.token_indexer.TokenIndexer from params {'namespace': 'source_tokens', 'type': 'single_id'} and extras {}\n",
      "03/17/2019 18:09:12 - INFO - allennlp.common.params -   dataset_reader.source_token_indexers.tokens.type = single_id\n",
      "03/17/2019 18:09:12 - INFO - allennlp.common.from_params -   instantiating class allennlp.data.token_indexers.single_id_token_indexer.SingleIdTokenIndexer from params {'namespace': 'source_tokens'} and extras {}\n",
      "03/17/2019 18:09:12 - INFO - allennlp.common.params -   dataset_reader.source_token_indexers.tokens.namespace = source_tokens\n",
      "03/17/2019 18:09:12 - INFO - allennlp.common.params -   dataset_reader.source_token_indexers.tokens.lowercase_tokens = False\n",
      "03/17/2019 18:09:12 - INFO - allennlp.common.params -   dataset_reader.source_token_indexers.tokens.start_tokens = None\n",
      "03/17/2019 18:09:12 - INFO - allennlp.common.params -   dataset_reader.source_token_indexers.tokens.end_tokens = None\n",
      "03/17/2019 18:09:12 - INFO - allennlp.common.params -   dataset_reader.lazy = False\n"
     ]
    }
   ],
   "source": [
    "from allennlp.models.archival import load_archive\n",
    "from allennlp.predictors import Seq2SeqPredictor\n",
    "\n",
    "archive = load_archive('./tmp_1/new_path.tar.gz')\n",
    "predictor = Seq2SeqPredictor.from_archive(archive, 'seq2seq')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'metadata': {'source_tokens': ['hello', 'world']},\n",
       " 'predicted_log_probs': [-5.522677421569824,\n",
       "  -10.58518123626709,\n",
       "  -10.632318496704102,\n",
       "  -10.70541763305664,\n",
       "  -15.761268615722656],\n",
       " 'predictions': [[3, 3, 3], [6, 3, 3], [21, 3, 3], [40, 3, 3], [6, 13, 3]],\n",
       " 'predicted_tokens': [[], ['What'], ['Where'], ['take'], ['What', 'what']]}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.predict(\"hello world\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]03/17/2019 18:09:17 - INFO - allennlp.data.dataset_readers.copynet_seq2seq -   Reading instances from lines in file at: small_test.tsv\n",
      "100it [00:00, 213.39it/s]\n"
     ]
    }
   ],
   "source": [
    "validation_file=\"small_test.tsv\"\n",
    "reader = CopyNetDatasetReader(\n",
    "    target_namespace=\"target_tokens\",\n",
    "    source_tokenizer=WordTokenizer(),\n",
    "    target_tokenizer=WordTokenizer(),\n",
    "    source_token_indexers={'tokens': SingleIdTokenIndexer()},\n",
    "    #target_token_indexers={'tokens': SingleIdTokenIndexer(namespace='target_tokens')}\n",
    "    )\n",
    "validation_dataset = reader.read(validation_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SOURCE: [@start@, Iqbal, expressed, fears, that, not, only, would, #, STR, #, secularism, and, secular, nationalism, #, END, #, weaken, the, spiritual, foundations, of, Islam, and, Muslim, society, ,, but, that, India, 's, Hindu, -, majority, population, would, crowd, out, Muslim, heritage, ,, culture, and, political, influence, ., In, his, travels, to, Egypt, ,, Afghanistan, ,, Palestine, and, Syria, ,, he, promoted, ideas, of, greater, Islamic, political, co, -, operation, and, unity, ,, calling, for, the, shedding, of, nationalist, differences, ., Sir, Muhammad, Iqbal, was, elected, president, of, the, Muslim, League, in, 1930, at, its, session, in, Allahabad, as, well, as, for, the, session, in, Lahore, in, 1932, ., In, his, Allahabad, Address, on, 29, December, 1930, ,, Iqbal, outlined, a, vision, of, an, independent, state, for, Muslim, -, majority, provinces, in, northwestern, India, ., This, address, later, inspired, the, Pakistan, movement, ., @end@]\n",
      "GOLD: [@start@, What, did, Iqbal, fear, would, weaken, the, spiritual, foundations, of, Islam, and, Muslim, society, ?, @end@]\n",
      "PRED: [['the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the'], [',', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the'], ['of', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the'], ['the', ',', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the'], [',', ',', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the']]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "for instance in itertools.islice(validation_dataset, 1):\n",
    "    print('SOURCE:', instance.fields['source_tokens'].tokens)\n",
    "    print('GOLD:', instance.fields['target_tokens'].tokens)\n",
    "    print('PRED:', predictor.predict_instance(instance)['predicted_tokens'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python allennlp",
   "language": "python",
   "name": "allennlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
